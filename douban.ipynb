{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#下载豆瓣电影排行榜250\n",
    "下载网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DOWNLOAD_URL = 'http://movie.douban.com/top250'\n",
    "\n",
    "def download_page(url):\n",
    "    data = requests.get(url).content\n",
    "    return data\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(download_page(DOWNLOAD_URL))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候产生403\n",
    "原因，一般可能是因为需要登录的网站没有登录或者被服务器认为是爬虫而拒绝访问。一般，浏览器在向服务器发送请求的时候，会有一个请求头——User-Agent，它用来标识浏览器的类型.当我们使用requests来发送请求的时候，默认的User-Agent是python-requests/2.8.1（后面的数字可能不同，表示版本号）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DOWNLOAD_URL = 'http://movie.douban.com/top250/'\n",
    "\n",
    "\n",
    "def download_page(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'\n",
    "    }\n",
    "    data = requests.get(url, headers=headers).content\n",
    "    return data\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(download_page(DOWNLOAD_URL))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "DOWNLOAD_URL = 'http://movie.douban.com/top250/'\n",
    "\n",
    "\n",
    "def download_page(url):\n",
    "    return requests.get(url, headers={\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'\n",
    "    }).content\n",
    "\n",
    "\n",
    "def parse_html(html):\n",
    "    soup = BeautifulSoup(html)\n",
    "    movie_list_soup = soup.find('ol', attrs={'class': 'grid_view'})\n",
    "\n",
    "    movie_name_list = []\n",
    "\n",
    "    for movie_li in movie_list_soup.find_all('li'):\n",
    "        detail = movie_li.find('div', attrs={'class': 'hd'})\n",
    "        movie_name = detail.find('span', attrs={'class': 'title'}).getText()\n",
    "        movie_name_list.append(movie_name)\n",
    "\n",
    "    next_page = soup.find('span', attrs={'class': 'next'}).find('a')\n",
    "    if next_page:\n",
    "        return movie_name_list, DOWNLOAD_URL + next_page['href']\n",
    "    return movie_name_list, None\n",
    "\n",
    "\n",
    "def main():\n",
    "    url = DOWNLOAD_URL\n",
    "    dir = '/Users/apple/Desktop/movies.txt'\n",
    "    with open(dir, 'a', encoding='utf-8') as fp:\n",
    "        while url:\n",
    "            html = download_page(url)\n",
    "            movies, url = parse_html(html)\n",
    "            #fp.write(u'{movies}\\n'.format(movies='\\n'.join(movies)))\n",
    "            fp.writelines('\\n'.join(movies))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
